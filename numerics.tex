%!TEX root = kdv.tex
%%%%%%%%%%%%%%%%%%%%%%%
\section{Discretization and numerical results}
%%%%%%%%%%%%%%%%%%%%%%%
\label{secnum}
This section is devoted to the discretization of the optimization problem \eqref{cost}, as well as some insights into the numerical optimization process we use.
\subsection{Discretization of state and adjoint equation}
%One difficulty arising in the discretization of the \KdVB equation is the variety of temporal scales. While the effects of the nonlinearity are only visible after a long time interval, the linear part involves a wide range of scales: the third order derivative represents in particular a high frequency term.
In the case of bounded domains numerous schemes are available, for example finite difference schemes \cite{djidjeli1995numerical,zabusky1965interaction}, finite element schemes \cite{winther1980conservative,arnold1982superconvergent}, finite volume schemes \cite{dutykh2013finite}, discontinuous Galerkin schemes \cite{Bona1986859,yan2002local}, or polynomial spectral methods \cite{ma2000legendre,ma2001optimal,shen2003new}. One of the most recent and efficient method for the \KdV is proposed in \cite{ma2000legendre}. The linear term is treated by a Petrov-Galerkin method on the Legendre polynomials, whereas the nonlinear term is treated pseudospectrally on the Chebyschev collocation points. Shortly after, Shen \cite{shen2003new} proposed an improvement of this Petrov-Galerkin method with nearly optimal computational complexity. This will be our method of choice and we recall it here briefly. Since it has never been used on optimal control problems, we also discuss an appropriate time discretization which allows the derivation of a consistent adjoint time stepping.
%Moreover, it is also equivalent to a natural weighted spectral-Galerkin formulation. For those reasons,
%This will be our method of choice and we recall it here briefly. Since it has never been used on optimal control problem, we also discuss an appropriate discretization of the method regarding the time stepping scheme used.

% One of the most recent and efficient discretization method is a pseudospectral Petrov-Galerkin method on Chebyshev collocation points, as introduced in \cite{ma2000legendre}, and improved in \cite{shen2003new}.
%
%  With the aim of tackling an optimal control problem, spectral discretizations present interesting advantages compared to any finite difference or finite element method \cite{boydchebyshev}. First of all they provide very low approximation errors: in some simple cases, these approaches are even exponentially convergent. As a result, the number of grid points required to achieve the desired precision can be very low and the memory needed to store the variables less than for alternative methods. This is a very convenient feature in our perspective, where the optimization part requires the storage of the forward and backward problem in space and time. Finally, there exist nowadays high-performance implementations of the algorithms required to transform bases for most spectral methods. Because of the nonlinearity in the \KdVB equation,
%
%
% TO SUMMARIZE
%
% spectral collocation methods shall be favoured: they indeed allow to represent the variables in terms of their values on a set of points and not only as the coefficients in the spectral expansion. However, for third order equation, the authors show in \cite{merryfield1993properties} that Chebyshev and Legendre collocation methods are unstable. That is why pseudospectral method habe been popular for third order PDEs. Fourier pseudospectral methods have been extensively used \cite{trefethen2000spectral,maday1988error,fornberg1978numerical}. They are in particular very fast when combined with the Fast Fourier Transform to treat the nonlinear term on collocation points. Nevertheless, they are only suited for periodic boundary conditions. Polynomial pseudospectral method on the contrary, which are more adequate for bounded intervals, proved to be stable for the linear third-order differential equation with Chebyshev or Legendre Gauss Lobatto points as collocation points \cite{HuangSloan1992}. They have also demonstrated great performances compared to any other method (see the benchmarking in \cite{skogestad2009boundary}). An interesting hybrid method is proposed in \cite{ma2000legendre}, where the linear term is treated by a Petrov-Galerkin method (better suited for nonsymmetric problems) on Legendre polynomials, while the nonlinear term is treated pseudospectrally using a Chebyshev method. Shortly after, Shen \cite{shen2003new} proposed another dual Petrov-Galerkin method with nearly optimal computational complexity. Moreover, it is also equivalent to a natural weighted spectral-Galerkin formulation. For those reasons, this will be our method of choice and we recall it here briefly. Since it has never been used on optimal control problem, we also discuss an appropriate discretization of the method regarding the time stepping scheme used.

\subsubsection{The dual Petrov-Galerkin method}
The interesting feature of this method lies in the choice of the test and trial functions bases. They are chosen as a compact (adjacent orders) combination of Legendre polynomials such that the trial functions satisfy the underlying boundary conditions of \eqref{kdvlinnonhom2} and the test functions satisfy the dual boundary conditions \eqref{kdvlinnonhomdual2}. Therefore, most matrices, i.e. mass matrices and stiffness matrices, involved are sparse or well-conditioned, cf. \cite{shen2003new}. We present the method on some reference domain $[-1,1]$, but it can be extended to any other domain of type $[a,b]$ by scaling the Legendre polynomials and the integrals. {\color{red} Throughout the following sections we assume $\gamma\geq0$, ie. all discussed results apply in the viscous as well as the non-viscous case.} Then we denote by $P_N$ the space of polynomials of degree $\leq N$ and set
\be
V_N = \left\{y\in P_N : y(1)=y(-1)=\partial_x y(1)=0\right\},
\ee
\be
V_N^{\ast} = \left\{y\in P_N : y(1) = y(-1) = \partial_x y(-1)=0\right\}.
\ee
We consider then the semi-discrete problem: Find
\be\nonumber
y_N\colon I \rightarrow V_N,\quad t \mapsto y_N(t,\cdot),
\ee
such that for almost every $t\in I$
\begin{multline}
(\partial_t y_N , \varphi_N) + \left(\partial_xy_N,\varphi_N \right) + \left(\partial_x y_N, \partial_{xx}\varphi_N \right)  + \\ \gamma \left( \partial_x y_N, \partial_x \varphi_N \right)- \left(\frac{y_N^2}{2}, \partial_x \varphi_N\right)= \langle u, \varphi_N\rangle_{\M,\C}, \quad \forall \varphi_N \in V_N^{\ast},
\label{petrovgalerkin}
\end{multline}
holds where $\left( \cdot, \cdot \right)$ denotes the usual $L^2(\Omega)$-inner product. %Let us point out that the weak solution of \eqref{kdvlinnonhom1} - \eqref{kdvlinnonhom3} has $\mathcal{B}\cap H^1(I,\mathcal{V}^*)$ regularity, and therfore also satisfies \eqref{petrovgalerkin} for all test functions in $\mathcal{V}$.
Denoting by $L_k$ the $k$th Legendre polynomial, we can define the basis functions as follows (see \cref{basisfunctions})
\be
\phi_k(x) = L_k(x) - \frac{2k+3}{2k+5}L_{k+1}(x) - L_{k+2}(x) + \frac{2k+3}{2k+5}L_{k+3}(x),
\ee
\be
\psi_k(x) = L_k(x) + \frac{2k+3}{2k+5}L_{k+1}(x) - L_{k+2}(x) - \frac{2k+3}{2k+5}L_{k+3}(x).
\ee
%\input{plotbasis}
\begin{center}
\begin{figure}[!h]
\includegraphics[scale=0.6,angle=270]{images/plotbasis2.pdf}
\caption{First test and trial functions.}
\label{basisfunctions}
\end{figure}
\end{center}


Thus for $N \geq 3$, we have
\beal
&V_N = \operatorname{span} \left\{ \phi_0,\phi_1,...,\phi_{N-3}\right\},\\
&V_N^{\ast} = \operatorname{span} \left\{ \psi_0,\psi_1,...,\psi_{N-3}\right\}.
\eeal
Then, we introduce the semi-discrete state variable $y_{N}(t,\cdot)$ on spectral space and its vector representation:
\be
y_N(t,\cdot) = \sum_{k=0}^{N-3}{\hat y_k(t)\phi_k(\cdot)},\quad \mathbf{y}(t) = \left( \hat y_0(t), \hat y_1(t), ..., \hat y_{N-3}(t)\right)^T.
\ee
The vector representation of the control is given by:
\be
\mathbf{u}(t) = \left( \langle u_{N}(t,\cdot), \psi_0(\cdot) \rangle, \langle u_{N}(t,\cdot), \psi_1(\cdot) \rangle, ..., \langle u_{N}(t,\cdot), \psi_{N-3}(\cdot) \rangle\right)^T
\label{discrcontrol}
\ee
where the form of the semi-discrete control $u_{N}(t,\cdot)$ is given in \cref{secdiscrcontrol}. Based on these discrete spaces, we build the matrices $M$, $P$, $Q$ and $S$ of size $(N-2)\times(N-2)$ with the coefficients $m_{ij}, p_{ij}, q_{ij}$ and $s_{ij}$ defined as follows:
\be
m_{ij}=(\phi_j, \psi_i),\quad p_{ij}=(\partial_x\phi_j, \psi_i),\quad q_{ij}=(\partial_x\phi_j, \partial_x\psi_i),\quad s_{ij}=(\partial_x\phi_j,\partial_{xx}\psi_i).
\label{definitionsmatrices}
\ee
The variational formulation \eqref{petrovgalerkin} thus yields
\be
M\frac{d\mathbf{y}}{dt} + \left(P +\gamma Q  + S \right)\mathbf{y} + F(\mathbf{y}) = \mathbf{u},
\ee
%<<<<<<< HEAD
%where $F(\mathbf{y})$ is the nonlinear term and is treated as suggested in \cite{shen2003new} i.e. using the pseudospectral approach. This means that the nonlinearity is evaluated in the spatial domain given by Chebyshev-Gauss-Lobatto (CGL) points, and is transferred back in the Legendre spectral space. Therefore, we need to be able to transform back and forth from the spectral space of Legendre coefficients to the values on the CGL points. This can be done using the fast Fourier transform (FFT) and the Chebyshev-Legendre transform. However, for the polynomial degrees we consider here (between 160 and 512), we use a simpler and more direct method which is faster and allows for an easier derivation of the discrete adjoint state equation (see \cref{numadjoint}). Beforehand we build the matrices  $L_1 =\left(\phi_j(x_i)\right)$ and $L_2 =\left(\psi_j(x_i)\right)$, $i=0 \ldots N$, $j=0 \ldots N-3$, where the points $x_i$ are the CGL points. By construction, those matrices satisfy
%=======
where $F(\mathbf{y})$ is the nonlinear term and is treated as suggested in \cite{shen2003new} i.e. using the pseudospectral approach. This means that the nonlinearity is evaluated in the spatial domain given by Chebyshev-Gauss-Lobatto (CGL) points, and is transferred back in the Legendre spectral space. Therefore, we need to be able to transform back and forth from the spectral space of Legendre coefficients to the values in the CGL points. This can be done using the fast Fourier transform (FFT) and the Chebyshev-Legendre transform. However, for the polynomial degrees we consider here (between 160 and 512), we use a simpler and more direct method which is faster and allows for an easier derivation of the discrete adjoint state equation (see \cref{numadjoint}).  {\color{red} It consists of building the matrices  $L_1 =\left(\phi_j(x_i)\right)$ and $L_2 =\left(\psi_j(x_i)\right)$, $i=0 \ldots N$, $j=0 \ldots N-3$ beforehand, where the points $x_i$ are the CGL points. By construction, those matrices satisfy
\be
L_1 \mathbf{y}(t) = \mathbf{\tilde{y}}(t) = (y_N(t, x_0), y_N(t, x_2), ...y_N(t, x_{N}))^T,
\label{spec2spat}
\ee
and the same holds true for a variable from $V_N^\ast$ with $L_2$. Thus the evaluation of the nonlinear term is given by
\be
L_1 F(\mathbf{y}(t)) = \mathbf{\tilde{y}}^2(t) = (y_N^2(t, x_0), y_N^2(t, x_2), ...y_N^2(t, x_{N}))^T.
\label{spec2spat2}
\ee}
Note that the spatial space, in which $\mathbf{\tilde{y}}(t)$ lies, and the spectral space, in which $\mathbf{y}(t)$ lies, do not have the same dimensions, i.e. $N+1$ versus $N-2$. This is only caused by the fact that the three boundary conditions are already included in the spectral space and not in the spatial space.
% \subsection{Time stepping scheme and adjoint - Crank-Nicolson}
% We have to deal with a problem of high order derivative. Therefore an explicit temporal discretization would lead to excessively small time steps in order to get stability. An implicit method should rather be considered. In \cite{li2000error}, the authors prove convergence of a pseudospectral method with backward Euler scheme for the \KdV equation. However in practice, the first order accuracy in time authorizes only very small time steps. A second order implicit scheme like the Crank-Nicolson scheme should be preferable, though the resolution of the nonlinear system is computationally demanding. This scheme also has the advantage of being a method of choice in optimal control: using the representation of the Crank-Nicolson scheme as a continuous Galerkin method of degree one (continuous trial linear functions and discontinuous piecewise constant test functions) allows us to give directly the concrete form of the adjoint, tangent and additional adjoint equations leading to the exact computation of the discrete gradient and Hessian \cite{meidner2007adaptive}. Note that the use of discrete derivatives is important for the convergence of our optimization algorithm. The scheme for the state is
%
% \bealn
% &M \tilde y_0=M y_0\\
% &M \tilde y_{n+1} + \frac{\Delta t}{2}\left( (S +\gamma Q -P)\tilde y_{n+1} - F(\tilde y_{n+1})\right)  &=  M \tilde y_{n} + \frac{\Delta t}{2}\left( (S +\gamma Q-P)\tilde y_{n} - F(\tilde y_{n})\right)  \\
%  &  &+ \frac{\Delta t}{2}\left( M\tilde q_n + M \tilde q_{n+1}\right), \quad n=0..N.
% \eealn
%
% Then the discrete adjoint scheme in case of distributed control writes
% %\begin{equation}\left\{
% %\begin{split}
% %M^t p_{N+1} + \frac{\Delta t}{2}\left( (S^t +\gamma Q^t- P^t)p_{N+1} - F'(y_{N+1})^t p_{N+1}\right) = -\frac{\Delta t}{2} A(y_{N+1} - y_d)\\
% % M^t p_{n-1} +  \frac{\Delta t}{2}\left( (S^t  +\gamma Q^t- P^t)p_{n-1}  - F'(y_{n-1})^t p_{n-1}\right)  &= M^t p_{n}\\
% %&- \frac{\Delta t}{2}A((y_{n} - y_d)-(y_{n-1} - y_d))+\frac{\Delta t}{2}\left( (S^t +\gamma Q^t- P^t)p_{n} - F'(y_{n-1})^t p_{n}\right) ,\\
% %&n=2..N+1
% %\end{split}
% %\right.
% %\end{equation}
% \bealn
% &M^t p_{N+1} + \frac{\Delta t}{2}\left( (S^t +\gamma Q^t- P^t)p_{N+1} - F^{'}(y_{N+1})^t p_{N+1}\right) = -\frac{\Delta t}{2} A(y_{N+1} - y_d) \\
% &M^t p_{n-1} +  \frac{\Delta t}{2}\left( (S^t  +\gamma Q^t- P^t)p_{n-1}  - F(y_{n-1})^t p_{n-1}\right)  = M^t p_{n} \\
% & \mbox{\hspace{0.15\textwidth}}- \frac{\Delta t}{2}A((y_{n} - y_d)-(y_{n-1} - y_d) + \frac{\Delta t}{2}\left( (S^t +\gamma Q^t- P^t)p_{n} - F^{'}(y_{n-1})^t p_{n}\right) ,\\
% & \mbox{\hspace{0.6\textwidth}}n=2..N+1\\
% &M^t p_{0}  = M^t p_{1} + \frac{\Delta t}{2}\left( (S^t +\gamma Q^t- P^t)p_{1} - F^{'}(y_{0})^t p_{1}\right)-\frac{\Delta t}{2} A(y_{1} - y_d)
% \eealn
% where the matrix $A = \left( \langle \phi_i,\phi_j\rangle\right)$ comes from the discretization of the Lagrangian (in particular the $L^2$ norm in the cost function). We also give the case of the terminal observations problem because we will use it in our numerical examples.
% \bealn
% & M^t p_{N+1} + \frac{\Delta t}{2}\left( (S^t +\gamma Q^t- P^t)p_{N+1} - F^{'}(y_{N+1})^t p_{N+1}\right) = - A(y_{N+1} - y_d)\\
% & M^t p_{n-1} + \frac{\Delta t}{2}\left( (S^t +\gamma Q^t- P^t)p_{n-1} - F^{'}(y_{n-1})^t p_{n-1}\right)  = M^t p_{n} + \\
% & \mbox{\hspace{0.35\textwidth}}\frac{\Delta t}{2}\left( (S^t +\gamma Q^t- P^t)p_{n} - F^{'}(y_{n-1})^t p_{n}\right), \, n=2..N+1\\
% &M^t p_{0}  = M^t p_{1} + \frac{\Delta t}{2}\left( (S^t +\gamma Q^t- P^t)p_{1} - F^{'}(y_{0})^t p_{1}\right)
%  \eealn

\subsubsection{Semi-discretization of the control $u$}
\label{secdiscrcontrol}
By $\left\{x_i \right\}, i = 0, 1, \ldots, N$, we denote the grid points of the spatial mesh (i.e. in our case the CGL points). The control is then discretized as follows
\be
u_N(t, \cdot) = \sum_{j=0}^{N}{\hat u_j(t)\delta_{x_j}(\cdot)}
\ee
where $\delta_{x_j}$ are Dirac functionals located at the grid points $x_j$ and the functions $\hat u_j(t)$ are its time-dependent coefficients. Hence, there holds $u_N \in \M$. Thus the righthand side of \eqref{petrovgalerkin} takes the form
\be
\langle u_N(t),\psi\rangle = \sum_{j=0}^{N}{\hat u_j(t)\psi(x_j)}.
\label{discrpscontrol}
\ee
Moreover we introduce another vectorized representation of the variable $u_{N}$
\be
\mathbf{\hat u}(t) = \left( \hat u_{0}(t), \ldots, \hat u_{N}(t)\right)^{T}.
\label{discrcontrolindirac}
\ee
This representation of the discrete control will be useful in the definition of the various norms involved in the optimization process.
%as well as the norm in the objective functional
%\be
%\|{u_N}\|_{\M} = \sum_{j=1}^N{\left( \sum_{i = 1}^{N_T}{\tau_i u_{ji}^2}\right)^{1/2}},
%\ee
%where $N_T$ is the number of time steps and $\tau_i$ is the size of the $i^{th}$ step. We point out that this precise control discretization was also used and analyzed in \cite{pieper2013priori, pieper2014,casas2013parabolic}.

\subsubsection{Time stepping scheme and adjoint - Crank-Nicolson-Leap-Frog}
\label{numadjoint}
The \KdVB equation involves a high order derivative. Therefore an explicit temporal discretization would lead to small time steps in order to get stability. Thus an implicit method seems to be more more appropriate. In \cite{li2000error}, the authors prove convergence of a pseudospectral method in space combined with a backward Euler scheme for the \KdV equation. Due the first order convergence of this method, small time steps are required to achieve a good level of accuracy. Therefore, a second order implicit scheme like the Crank-Nicolson scheme is preferable. This scheme is well studied in the context of optimal control of PDEs. Using the representation of the Crank-Nicolson scheme as a Petrov-Galerkin method with continuous linear trial functions and discontinuous piecewise constant test functions determines the form of the discrete adjoint, tangent and additional adjoint equations. The solutions of these discrete equations are used for the exact computation of the discrete gradient and Hessian, e.g. \cite{meidner2007adaptive}. Note that the use of the exact discrete derivatives is important for the convergence of optimization algorithms. However, the Crank-Nicolson scheme is computationally demanding. An alternative is the two-step Crank-Nicolson-Leap-Frog (CNLF) method in which the third derivative is treated implicitly and the nonlinear term is treated explicitly. This method has already been extensively used for the \KdV equation, cf. \cite{shen2003new,ma2000legendre,ma2001optimal}.
%showing for instance extended stability intervals with the Fourier spectral method \cite{chan1985fourier}. However, to the authors' knowledge, this has never been used in the context of an optimal control problem.
Commonly, it is initialized by a semi-implicit step. We suggest also a slight modification of the last step of this two-step method in order to get a discrete adjoint state equation that is consistent with the continuous adjoint state equation.\\
The time domain is divided into $N_{T}$ intervals, i.e. $0 = t_0 < t_1....< t_{N_{T}} = T$. The first and last one have length $\frac{\Delta t}{2}$ and the other steps are of equal length $\Delta t$. The fully discrete state variable has the form
$$\mathbf{y}_n = \mathbf{y}(t_n) = \left( \hat y_0(t_n), \hat y_1(t_n), ..., \hat y_{N-3}(t_n)\right)^T,  \quad  n=0 \ldots N_{T}$$ and the control
\beal
&\mathbf{u}_n = \mathbf{u}(t_n) = \left( \langle u_{N}(t_n,\cdot), \psi_0(\cdot) \rangle, \langle u_{N}(t_n, \cdot), \psi_1(\cdot) \rangle, ..., \langle u_{N}(t_n, \cdot), \psi_{N-3}(\cdot) \rangle\right)^T, \\
&\mathbf{\hat u}_n = \mathbf{\hat u}(t_n) = \left( \hat u_{0}(t_{n}), \ldots, \hat u_{N}(t_{n})\right)^{T}, \quad  n=0 \ldots N_{T}
\eeal
where the duality pairing $\langle\cdot,\cdot\rangle$ is evaluated according to \eqref{discrpscontrol}. With the help of the matrices defined in \eqref{definitionsmatrices}, the forward scheme looks as follows
\bealn\label{forwardscheme}
& \frac{1}{2}\left( M+\Delta t S\right) \mathbf{y}_1 = \frac{1}{2}\left( M + \Delta t \left(P + \gamma  Q \right) \right) \mathbf{y}_0 + \frac{1}{2}\Delta t F(\mathbf{y}_0) + \frac{1}{2}\Delta t \mathbf{u}_0 \\
& \frac{1}{2}\left( M+\Delta t S\right) \mathbf{y}_{n+1} = \frac{1}{2}\left( M - \Delta t S\right) \mathbf{y}_{n-1} +  \Delta t \left( P + \gamma Q\right)\mathbf{y}_n \\
& \mbox{\hspace{0.5\textwidth}}+ \Delta t F(\mathbf{y}_n) + \Delta t \mathbf{u}_n,  \, n=1 \ldots N_{T}-1\\
& M \mathbf{y}_{N_{T}+1} = \frac{1}{2}\left( M \mathbf{y}_{N_{T}} + M \mathbf{y}_{N_{T}-1} \right)+ \frac{1}{2}\Delta t \left(P + \gamma Q \right)\mathbf{y}_{N_{T}} \\
& \mbox{\hspace{0.5\textwidth}} + \frac{1}{2}\Delta t F(\mathbf{y}_{N_{T}}) - \frac{1}{2}\Delta t S \mathbf{y}_{N_{T}-1}
\eealn
The first step is semi-implicit. The steps $n=1 \ldots N_{T}-1$ are classical CNLF steps. The last step is not a regular step. It is designed in a way such that the discrete adjoint state equation is consistent with a CNLF discretization of the continuous adjoint state equation. Notice, that this step becomes the mean value between the two preceding steps for $\Delta t\downarrow0$.
The corresponding discrete objective functional has the form
\begin{multline}
J_{N,N_{T}}(\mathbf{y}_{0}, \ldots, \mathbf{y}_{N_{T}}, \mathbf{u}_{0}, \ldots, \mathbf{u}_{N_{T}}) = \frac{1}{2}\sum_{i=1}^{N_{T}}{\Delta t \left(\mathbf{y}_{i} - \mathbf{z}_{1,i}\right)^{t}A \left(\mathbf{y}_{i} - \mathbf{z}_{1,i}\right)} + \\ \frac{1}{2}\left(\mathbf{y}_{N_T} - \mathbf{z}_{2}\right)^{t}A \left(\mathbf{y}_{N_T} - \mathbf{z}_{2}\right)
 + \alpha \sum_{j=1}^N{\left( \sum_{i = 1}^{N_T}{\Delta t \mathbf{\hat u}_{ij}^2}\right)^{1/2}}
\label{discrobj}
\end{multline}
where entries of $A$ are given by $a_{ij}=(\chi_{\Omega_o}\phi_j, \psi_i)_{L^2(\Omega)}$.
Then we define the discrete Lagrangian function:
\begin{multline}
\mathcal{L}_{N,N_{T}}(\mathbf{y}_{0}, \ldots, \mathbf{y}_{N_{T}},\mathbf{u}_{0}, \ldots, \mathbf{ u}_{N_{T}}, \mathbf{p}_{0}, \ldots, \mathbf{p}_{N_{T}-1}) = \\
J_{N,N_{T}}(\mathbf{y}_{0}, \ldots, \mathbf{y}_{N_{T}}, \mathbf{u}_{0}, \ldots, \mathbf{u}_{N_{T}})  +\\
\mathbf{p}_0^T\left[ \frac{1}{2}\left( M+\Delta t S\right) \mathbf{y}_1 - \frac{1}{2}\left( M + \Delta t P + \gamma \Delta t Q \right) \mathbf{y}_0 - \frac{1}{2}\Delta t F(\mathbf{y}_0) - \frac{1}{2}\Delta t \mathbf{u}_0 \right]+\\
\sum_{k=1}^{N_T-2}{\mathbf{p}_k^T\left[\frac{1}{2}\left( M+\Delta t S\right) \mathbf{y}_{k+1} - \frac{1}{2}\left( M - \Delta t S\right) \mathbf{y}_{k-1} - \Delta t \left( P + \gamma Q\right)y_k \right.}\\
\left.- \Delta t F(y_k) - \Delta t \mathbf{u}_k\right] + \\
\mathbf{p}_{N_T-1}^T\left[ M \mathbf{y}_{N_T} - \frac{1}{2}\left( M \mathbf{y}_{N_T-1} + M \mathbf{y}_{N_T-2} \right)- \frac{1}{2}\Delta t \left(P+ \gamma Q\right) \mathbf{y}_{N_T - 1} \right.\\ \left.- \frac{1}{2}\Delta t F(\mathbf{y}_{N_T-1}) +\frac{1}{2}\Delta t S \mathbf{y}_{N_T-2}\right].
\label{discrlag}
\end{multline}
From \eqref{discrlag}, we can derive the discrete adjoint state equation which has the form
 \bealn
 &M^T \mathbf{p}_{N_T-1} = -A(\mathbf{y}_{N_T} - \mathbf{z}_2)\\
 &\frac{1}{2}\left( M^T+\Delta t S^T\right) \mathbf{p}_{N_T-2} = \frac{1}{2}\left( M^T + \Delta t P^T + \gamma \Delta t Q^T \right) \mathbf{p}_{N_T - 1} \\
 &\mbox{\hspace{0.3\textwidth}} + \frac{1}{2}\Delta t F^{'}(\mathbf{y}_{N_T - 1})^T \mathbf{p}_{N_T - 1} \\
 &\frac{1}{2}\left( M^T + \Delta t S^T\right)\mathbf{p}_{n-2} = \frac{1}{2}\left( M^T - \Delta t S^T\right)\mathbf{p}_{n} + \Delta t \left( P^T + \gamma Q^T\right)\mathbf{p}_{n-1} \\
 &\mbox{\hspace{0.3\textwidth}}+ \Delta t F^{'}(\mathbf{y}_{n-1})^T \mathbf{p}_{n-1},\quad n=2 \ldots N_T - 1.
 \label{numschemeadj}
\eealn
in the case of terminal observations, which will be of particular interest in the numerical examples. In the first equation the terminal value of the discrete adjoint state is set. This is followed by a single semi-implicit step and regular CNLF steps.
% The lagrangian of the problem writes at the continuous level.
% \beal
%   \mathcal{L}(y,q,p) = \frac{1}{2}\norm{y - y_d}_{\lspace}^2 + \alpha \norm{q}_{\M} + <p, By-q>
% \eeal
% Its (almost) discrete counterpart shall be
% \begin{multline}
% L(\bar y, \bar q, \bar p) = \frac{1}{2}(y_{N+1} - y_d)^t A (y_{N+1} - y_d) + \alpha \norm{q}_{\M} \\
% + p_0^t\left[ \frac{1}{2}\left( M+\Delta t S\right) y_1 - \frac{1}{2}\left( M + \Delta t P + \gamma \Delta t Q \right) y_0 - \frac{1}{2}\Delta t F(y_0) - \frac{1}{2}\Delta t M q_0 \right]\\
% +\sum_{k=1}^{N-1}{p_k^t\left[
% \frac{1}{2}\left( M+\Delta t S\right) y_{k+1} - \frac{1}{2}\left( M - \Delta t S\right) y_{k-1} - \Delta t \left( P + \gamma Q\right)y_k - \Delta t F(y_k) - \Delta t M q_k\right]}\\
% +p_N^t\left[ M y_{N+1} - \frac{1}{2}\left( M y_N + M y_{N-1} \right)- \frac{1}{2}\Delta t P y_N - \frac{1}{2}\Delta t F(y_N) +\frac{1}{2}\Delta t S y_{N-1}\right].
% \end{multline}
% Differentiating with respect to $\bar y$ leads
% \begin{multline}
% \delta L(\bar y, \bar q, \bar p)\delta \bar y = \delta y_{N+1}^t A (\delta y_{N+1} - y_d) \\
% + p_0^t\left[ \frac{1}{2}\left( M+\Delta t S\right) \delta y_1 - \frac{1}{2}\left( M + \Delta t P + \gamma \Delta t Q \right) \delta y_0 - \frac{1}{2}\Delta t F'(y_0)\delta y_0\right]\\
% +\sum_{k=1}^{N-1}{p_k^t\left[
% \frac{1}{2}\left( M+\Delta t S\right) \delta y_{k+1} - \frac{1}{2}\left( M - \Delta t S\right) \delta y_{k-1} - \Delta t \left( P + \gamma Q\right)y_k - \Delta t F'(y_k)\delta y_k \right]}\\
% +p_N^t\left[ M \delta y_{N+1} - \frac{1}{2}\left( M \delta y_N + M \delta y_{N-1} \right)- \frac{1}{2}\Delta t P \delta y_N - \frac{1}{2}\Delta t F'(y_N)\delta y_N + \frac{1}{2}\Delta tS\delta y_{N-1}\right]
% \end{multline}
% Symmetry of the scalar product yields, after re-indexing of the terms
% \beal
% \delta L(\bar y, \bar q, \bar p)\delta \bar y &= \delta y_{N+1}^t A (\delta y_{N+1} - y_d) \\
% &+ \left[ \delta y_1^t\frac{1}{2}\left( M+\Delta t S\right)  - \delta y_0^t\frac{1}{2} \left( M + \Delta t P + \gamma \Delta t Q \right) - \delta y_0^t\frac{1}{2}\Delta t F^{'}(y_0)\right]p_0\\
% &+\sum_{k=2}^{N}{\delta y_k^t\left[
% \frac{1}{2}\left( M+\Delta t S\right)^t \right]p_{k-1}}-\sum_{k=0}^{N-2}{\delta y_k^t\left[\frac{1}{2}\left( M+\Delta t S\right)^t \right]p_{k+1}}\\
% &-\sum_{k=1}^{N-1}{\left[ \delta y_k^t \Delta t\left(P^t + \gamma Q^t + F^{'}(y_k)^t\right)\right]p_k}\\
% &+\delta y_{N+1}^t M^t p_N - \delta y_{N-1}^t \frac{1}{2}(M^t - \Delta t S^t)p_N \\
% &-\delta y_{N}^t \left( \frac{1}{2}(M^t + \Delta t P^t + \Delta t F^{'}(y_N)^t) \right)p_N.
% \eeal
% The discrete adjoint scheme is obtained by imposing $\delta L(\bar y, \bar q, \bar p)\delta \bar y = 0$.
\begin{remark}
Without this modification of the last step in \eqref{forwardscheme}, the discrete adjoint state equation obtained in the case of terminal observation would be
\bealn
&\frac{1}{2}(M^T+\Delta t S^T) \mathbf{p}_{N_T-1} = -A(\mathbf{y}_{N_T} - \mathbf{z}_2)\\
&\frac{1}{2}\left( M^T+\Delta t S^T\right) \mathbf{p}_{N_T-2} =  \left(\Delta t P^T + \gamma \Delta t Q^T \right) \mathbf{p}_{N_T-1} + \Delta t F^{'}(\mathbf{y}_{N_T - 1})^T \mathbf{p}_{N_T - 1} \\
&\frac{1}{2}\left( M^T + \Delta t S^T\right)\mathbf{p}_{n-2} = \frac{1}{2}\left( M^T - \Delta t S^T\right)\mathbf{p}_{n} + \Delta t \left( P^T + \gamma Q^T\right)\mathbf{p}_{n-1} \\
&\mbox{\hspace{0.4\textwidth}}+ \Delta t F^{'}(\mathbf{y}_{n-1})^T \mathbf{p}_{n-1}, \quad n=2 \ldots N_T-1.
\eealn
The major difference is the second step. It does not correspond to a consistent discretization of the continuous adjoint state equation. The time derivative is not reconstructed. In practice this would result in large oscillations in time of the adjoint variable.
\end{remark}
\begin{remark}
Unlike the other steps, the modified last step in \eqref{forwardscheme} involves the inversion of the matrix $M$, which is typically ill-conditioned. Therefore, we invert the matrix $M+\varepsilon Id$ with a $\varepsilon$ of the order $h^2$, where $h$ is the largest space step.
\end{remark}
\begin{proposition}
The directional derivative of
\[
\{\mathbf u_i\}_{i=1}^{N_T}\mapsto\frac{1}{2}\left(\mathbf{y}_{N_T} - \mathbf{z}_{2}\right)^{t}A \left(\mathbf{y}_{N_T} - \mathbf{z}_{2}\right),
\]
where $\{\mathbf y_i\}_{i=1}^{N_T}$ is the solution of \eqref{forwardscheme}, is given by $\{-\mathbf{p}_i\}_{i=1}^{N_T}$, where $\{\mathbf{p}_i\}_{i=1}^{N_T}$ is the solution of \eqref{numschemeadj}.
\end{proposition}
\begin{proof}
The proof is done by standard differentiation of the discrete Lagrangian.
\qquad\end{proof}

\subsection{Numerical treatment of the optimization problem}
{\color{red} In this section we consider the optimal control problem \eqref{cost} in both the viscous and non-viscous case, i.e. $\gamma\geq0$, without additional norm-constraints on the control. Thus we have $U_{ad}=\M$.}
\subsubsection{The regularized problem}
In this section, we discuss the solution of the optimal control problem \eqref{cost} by Newton type method and a continuation strategy. We introduce an additional $L^2$ regularization term in \eqref{cost}:
\begin{multline}
\min_{u \in L^2(\Omega_c\times I), y\in Y}J(y,u)=\frac{1}{2}\left(\norm{\chi_{\Omega_{o}}y - z_1}_{L^2(I\times \Omega_{o})}^2+\|\chi_{\Omega_{o}}y(T)-z_2\|_{L^2(\Omega_{o})}^2\right)\\
+\alpha \norm{u}_{L^1(\Omega_c, L^{2}(I))} + \frac{\rg}{2}\norm{u}_{L^2(I\times\Omega_c)}^2\quad\text{s.t.}~\eqref{kdvcontrol1}-\eqref{kdvcontrol3}.
\label{costreg}
\end{multline}
%\beal
%\min_{u \in \M} J(y) &= \frac{1}{2}\norm{y - y_d}_{\lspace}^2 + \alpha \norm{u}_{L^1(\Omega,L^2(I))} + \frac{\rg}{2}\norm{u}_{L^2(\Omega,L^2(I))}^2 \\
%& = f(y) + \alpha \norm{u}_{L^1(\Omega,L^2(I))} + \frac{\rg}{2}\norm{u}_{L^2(\Omega,L^2(I))}^2,
%\label{costreg}
%\eeal
This problem is posed in the Hilbert space $L^2(I\times\Omega_c)$. Since the embedding $L^1(\Omega_c,L^2(I))\hookrightarrow \M$ is isometric, we have
\be
\psi(u) = \norm{u}_{\M} = \norm{u}_{L^1(I,L^2(\Omega_c))} = \int_{\Omega_c}{\norm{u(x)}_{L^2(I)}dx}.
\ee
for any $L^2(I\times \Omega_c)$. In \cite{herzog2012directional}, the authors study this problem in the linear parabolic case, and prove that this setting promotes a \textit{striped sparsity pattern} of the optimal control. For the derivation of optimality conditions, we introduce the proximal map of the $L^1(\Omega_c, L^{2}(I))$ norm, e.g. \cite{bauschke2011convex}:
\be
\operatorname{Prox}_{\psi/ \rg}(q)(t,x) = \left(1-\frac{\alpha}{\rg\norm{q(x)}_{L^{2}(I)}}\right)^{+}q(t,x) \quad \mbox{ for } q \in L^{2}(I\times\Omega_c).
\ee
We can then express the optimality condition for \eqref{costreg} by the pointwise formula
\be
\bar u_{\rg}(t,x) = \operatorname{Prox}_{\psi/ \rg}\left(-\frac 1\rg \bar p_\rg\right)(t,x)=-\frac{1}{\rg}\left( 1 - \frac{\alpha}{\norm{\bar p_{\rg}(x)}_{L^{2}(I)}}\right)^{+}\bar p_{\rg}(t,x)
\ee
with $\bar p_\rg(\bar u_\rg)=S_{obs}'^\star(\bar u_\rg)(S_{obs}\bar u_\rg-z)$ and $z=(z_1,z_2)$. Now a Newton type method can applied for the solution of
\be
F(u_{\rg})(t,x) = \rg u_{\rg}(t,x) + \left( 1 - \frac{\alpha}{\norm{p_{\rg}(x)}_{L^{2}(I)}}\right)^{+}p_{\rg}(t,x) = 0.
\label{optcondition}
\ee
However, we follow \cite{pieperthesis} and reformulate the optimality condition \eqref{optcondition} using the "normal map" due to Robinson:
\be
\operatorname{G}(q_{\rg}) = \rg q_{\rg} + p_{\rg}(\operatorname{Prox}_{\psi/ \rg}(q_{\rg})) = 0,
\label{normalmap}
\ee
for the auxiliary variable $q_{\rg}$.  %such that $u_{\rg} = \operatorname{Prox}_{\psi/ \rg}(q_{\rg})$ h. %One easily prove in that case that $q_{\rg} = -\frac{1}{\rg} p_{\rg}$ and equivalence between \eqref{optcondition} and \eqref{normalmap}.

% and we can adapt it to state the following theorem
% \begin{thm}
%  Let $\gamma > 0$. Problem \eqref{costreg} possesses a unique optimal solution  $q_{\gamma} \in L^2(I\times\Omega)$ with corresponding state $y_{\gamma} = S(y_0,q_{\gamma})$ and adjoint state $p_{\gamma} = S'^{\ast}(y_{\epsilon} - y_d)$. The first order optimality condition is the subgradient condition
%  \be
%  -<q - q_{\gamma}, \frac{1}{\gamma}q_{\gamma} + p_{\gamma}> +\alpha \norm{q_{\gamma}}_{L^1(I,L^2(\Omega))} \leq \alpha \norm{q}_{L^1(I,L^2(\Omega))}
%  \ee
%  for all $q \in L^1(I,L^2(\Omega))$. This is summed up in the formula
%  \be
%  u_{\gamma}(t,x) = \gamma\max\left(0,1-\frac{\alpha}{\norm{p_{\gamma}}_{L^2(I)}}\right)p_{\gamma}(t,x)
%  \ee
%  for almost all $(t,x)\in I\times\Omega$.
% \end{thm}
% The idea is then to solve with a semismooth Newton method \cite{ulbrich2002semismooth} the equation
% \be
% F(q_{\gamma}) = q_{\gamma} - \gamma\max\left(0,1-\frac{\alpha}{\norm{p_{\gamma}}_{L^2(I)}}\right)p_{\gamma}(t,x)
% \ee
% In comparison to what is done in \cite{herzog2012directional}, the nonlinearity in our problem requires that we additionally compute the tangent and the second adjoint operators to get the gradient of $F$. Besides, in \cite{pieper2014}, the authors quickly prove that we obtain the original problem in the limiting case for great $\gamma$.
For the solution of problem \eqref{normalmap}, we apply a Newton-type method, and since the proximal operator is not differentiable, we use the concept of semismoothness to derive a generalized derivative for $\operatorname{G}$, cf. \cite{ulbrich2002semismooth}.  {\color{red}To be more precise, we have
\be
\operatorname{DG}(q_{\rg}) = \rg \operatorname{Id} + S_{obs}'^\star(y_\rg)B(q_\rg)S_{obs}'(y_\rg)\operatorname{DProx}_{\psi/ \rg}(q_{\rg}),
\ee
where $y_\rg=S_{obs}\operatorname{Prox}_{\psi/ \rg}(q_{\rg})$, $B(p_\rg)=1+\partial_xp_\rg(\operatorname{Prox}_{\psi/ \rg}(q_{\rg}))$ and the generalized derivative of the proximal map is given by
\begin{numcases}{\operatorname{DProx}_{\psi/ \rg}(q_{\rg})\delta q_{\rg} = }
\left(1-\frac{\alpha}{\rg\norm{q_{\rg}}_{L^{2}(I)}}\right)\delta q_{\rg}(x) + \frac\alpha\rg \frac{\left( q_{\rg}, \delta q_{\rg}\right)_{L^2(I)}}{\norm{q_{\rg}}_{L^{2}(I)}^3}q_{\rg} & \nonumber \\
 & \hspace{-1.5cm} \mbox{if   $\norm{q_{\rg}}_{L^{2}(I)} > \frac{\alpha}{\rg} $}\nonumber\\
0 & \mbox{otherwise.}
\end{numcases}}
The great advantage of the normal map approach is that the Newton operator $DG(q_{\rg})$ is symmetric with respect to the scalar product $(\cdot,\operatorname{DProx}_{\psi/ \rg}(q_{\rg})\cdot)_{L^2(I\times\Omega_c)}$, cf. \cite{PieperRund2015,pieperthesis}. Therefore the conjugate gradient method can be used to solve the Newton system. The operator $DF(u_\rg)$ is in general not symmetric. In the case of a linear state equation numerical experiments show that the continuation strategy in $\rg$ is sufficient to achieve global convergence, e.g. \cite{ClasonKunisch:2011b}. This is not the case for our problem due to the nonlinearity of the state equation. Additional to the continuation strategy in $\rg$ a globalization strategy based on the decrease of the regularized objective functional is required. We implement a trust region semi-smooth Newton based on the truncated conjugate gradient algorithm by Steihaug \cite{pieperthesis,steihaug1983}.  {\color{red}A concise explanation is also available in \cite[Section 6.2 and A.3]{PieperRund2015}}.

\subsubsection{Discretization of the control and mass lumping}
In the unregularized problem, the controls are discretized as nodal Dirac measures. In the regularized case, this is not possible due to $L^2(I\times\Omega_c)$ regularization term. Thus we introduce a discretization of the control which is compatible to the Dirac discretization in the limiting case $\rg \to 0$, i.e. we follow the strategy in \cite{pieper2014}. The control is discretized in space with piecewise linear and continuous finite elements on a grid whose nodes are given by the CGL-points $(x_n)$, $n=0 \ldots N$ previously mentioned.
% The finite element space associated with this grid is
% \be
% V_h = \left\{ u_h \in \mathcal{C}_0 (\Omega) \,|\, u_{h|K} \in \mathcal{P}_1(K) \mbox{ for all } K \in \mathcal{T}_h \mbox{ and } u_{h|\partial \Omega} = 0 \right\}.
% \ee
% The discretization parameter h denotes the maximum length of the intervals defined by the CGL points. For the time discretization, we define for any Banach space $V$ the semi-discrete space
% \be
% X_\tau^0 (I,V) = \left\{ v_{\tau} \in L^2(I,V) \, | \, v_{\tau|I_m} \in P_0(I_m,V), m=1..N_T\right\},
% \ee
% where $I_m = (t_{m-1}, t_m]$ and $0 = t_0 < t_1....< t_m = T$. The time steps are denoted $\tau_m = t_m - t_{m-1}$ and by $\tau$ we designate the maximum of them. The full discrete space for the control is then $X_{\tau}^0(I,V_h)$.
Thus, the discrete control has the form
\[
u_h = \sum_{j=1}^{N_T}{\chi_{I_j}\sum_{n=0}^{N}{\mathbf{\hat u}_{jn} e_n}},
\]
where $\chi_{I_j}$, $I_{j} = (t_{j-1}, t_j]$ is the characteristic function of the $j^{th}$ time interval, and $e_{n}$ is the finite element basis function centered at the grid point $x_{n}$. All scalar products and norms involving the discrete control are computed using mass lumping, i.e. the trapezoidal rule is used for the evaluation of the spatial integrals on each cell. Therefore, we have
\beal
&\norm{u_h}_{L^1(\Omega, L^2(I))} = \sum_{n=0}^N{d_n\left(\sum_{j=1}^{N_T}{\Delta t \mathbf{\hat u}_{nj}^2}\right)^{1/2}}, \quad \norm{u_h}_{L^2(\Omega, L^2(I))}^2 = \sum_{n=0}^N{d_n\left(\sum_{j=1}^{N_T}{\Delta t \mathbf{\hat u}_{nj}^2}\right)},\\
&\langle u_h,\psi \rangle_{L^2(\Omega)} = \sum_{j=1}^{N_T} \chi_{I_j} \sum_{n=0}^N{d_n \mathbf{\hat u}_{jn}\psi_{n}}
\label{masslumping}
\eeal
for all spectral basis functions $\psi$ where $\psi_n = \psi(x_n)$ and $d_n = \int_{\Omega_c}{e_n~\mathrm{d}x}$.
%$\varphi_h = \sum_{j=1}^{N_T}{\chi_{I_j}\sum_n{\varphi_{jn} e_n}}$.

\begin{remark}
Due to the use of \eqref{masslumping}, the formulas \eqref{optcondition} resp. \eqref{normalmap} hold also on the discrete level.
\end{remark}


\subsection{Numerical examples}\label{num_ex}
In this section, we investigate an inverse problem involving the flow of water in a narrow channel and the problem of the optimal positioning and vertical movement of a wavemaker. A similar optimal design problem is carried out in \cite{nersisyan2014generation}. A possible application is the design of artificial surfing facilities. For that purpose, we use a version of the forced \KdV equation with physical motivated parameters, as in \cite{milewski2004forced}:
\be
\partial_t y + f \partial_x y - \frac{1}{6}\partial_{xxx} y - \frac{3}{2}y \partial_x y = u
\label{PhysicalKDV}
\ee
where the parameter $f$ is proportional to $F-1$ ($F$ is the Froude number). Its value determines if a flow is subcritical ($f\leq 0$) or supercritical ($f> 0 $). The forcing $u$ is interpreted as the spatial derivative of the bottom topography of the channel. In both examples, we consider the minimization problem
\be
\min_{u \in \mathcal{M}(\Omega_c,L^2(I)), y\in Y}J(y,u) =\frac{1}{2}\|\chi_{\Omega_{o}}y(T)-z\|_{L^2(\Omega_{o})}^2 +\alpha \norm{u}_{\mathcal{M}(\Omega_c, L^{2}(I))}
\ee
for different $\Omega_c$, $\Omega_o$ and $z$, where $y$ is the solution of \eqref{PhysicalKDV}. In particular, we emphasize that $U_{ad} = \mathcal{M}(\Omega_c,L^2(I))$ and $\gamma=0$. In all numerical examples, we have never encountered blow ups of $y$.

\paragraph{\underline{Inverse problem}}
In the first example, we reconstruct the time-varying bottom topography which creates water waves in a narrow channel. These waves are observed at final time T. We generate beforehand a wave with the following source term
\begin{numcases}
{u^\dag(t,x) = }
 \nonumber 10\delta_{\{x = 1.5\}}, \mbox{ when } 0 < t\leq 2.5 \\
 0, \mbox{ when } 2.5 \leq t\leq 5
 \label{forcingq}
\end{numcases}
in a subcritical configuration ($f = -0.5$). The time horizon is $T = 5$. The space-time grid is parametrized with $N = 256$ spatial grid points and a time-step size of $\Delta t = 0.01$. The generated wave is displayed in \cref{waveobservation}.
\begin{figure}[htb]
\subfloat{\includegraphics[width=0.48\textwidth]{images/ex1yd3D.pdf}}\quad
\subfloat{\input{images/desired_state_inverse.tex}}
\caption{Left: Exact wave $y^\dag$ generated by the forcing term $u$, Right: $z$-profile at terminal time with Gaussian white noise.}
\label{waveobservation}
\end{figure}
One can see a series of downstream waves (note that the flow enters the domain from the right) and a solitary wave going upstream generated by the bottom topography induced by $u$. Then, white Gaussian noise is added to the $y^\dag$ at final time $T$. The magnitude of the noise is in average 5 percent of the magnitude of the original wave \[\frac{\norm{y^\dag - z}_{L^2(I\times \Omega)}}{\norm{y^\dag}_{L^2(I\times \Omega)}} \approx 0.05.\]
Next, we discuss our numerical results. The support of the optimal control is a subset of the sets where $\|\bar p(x)\|_{L^2(I)} = \alpha$ holds, see \cref{support} and \cref{propsubgcondition}. Thus, the optimal control is a point source, located close to $x=1.5$. The time profile of this point source is depicted in \cref{support} and it follows the original one quite well.
\begin{figure}[htb]
\centering
\subfloat{\input{images/normp_inverse}}
\subfloat{\input{images/control_inverse}}\quad
\caption{Left: Spatial support of the control determined by $\norm{\bar p(x)}_{L^2(I)} = \alpha$. Here $\alpha = 0.1$ and $\rg = 10^{-6}$. Right: Recovered intensity $\bar u(t)$ and exact intensity $u^\dag(t)$ }
\label{support}
\end{figure}
%We point out that the oscillations are caused by the noise. The noisy observation enters the adjoint equation as initial condition and the time profile of $\bar u$ is proportional to $t\mapsto\bar p(t,\hat x)$, where $\hat x$ is the reconstructed position of the point source. The results of the optimization process are shown on \cref{recoveredstate}, for $\alpha = 0.1$.
% \begin{figure}[!h]
%  \includegraphics[width = 0.45\textwidth]{images/ex1recoveredcontrol2.pdf}
%  \caption{Recovered control for $\rg = 10^{-6}$}
%  \label{recoveredcontrol}
% \end{figure}
In \cref{recoveredstate}, the recovered state on $I\times \Omega$ and on $\{T\}\times\Omega$ is depicted. We have a quite good tracking of $y^\dag(T)$.
\begin{figure}[htb]
\centering
\subfloat{\includegraphics[width =0.48\textwidth]{images/ex1recoveredstate3d.pdf}}\quad
\subfloat{\input{images/terminal_value_inverse}}
\caption{Recovered state $\bar y$ and terminal state $\bar y(T)$}
\label{recoveredstate}
\end{figure}

\paragraph{\underline{Control example}}
 The second example is a control example which is concerned with the optimal placement of bumps on the bottom of a narrow channel for the generation of a desired flow. We divide the domain $\Omega = [-L,L]$, $L=30$ into two subdomains. The domain $\Omega_c = [-L,0]$ is the control domain, while $\Omega_{o} = [0,L]$ is the observation domain, see \cref{controlsetup} for the description of the setup. The flow enters the domain from the right and we want to create the flow profile $z$ shown in \cref{controlsetup} on $\Omega_{o}$ at final time $T$, acting only on $\Omega_c$. Here the space-time grid is parametrized with $N = 512$ spatial grid points and a time-step size of $\Delta t = 0.01$.
\begin{figure}[htb]
\centering
\subfloat{\includegraphics[width=0.48\textwidth, height=3cm]{images/control_setup.png}}\quad
\subfloat{\input{images/desired_state}}
\caption{Control setup and data}
\label{controlsetup}
\end{figure}
 %\begin{figure}[!h]
% \includegraphics[width = 0.75\textwidth]{images/ex2yd.pdf}
% \caption{Objective wave at final time T.}
% \label{objectivewave}
% \end{figure}
Next, we review our numerical results. In \cref{recoveredcontrol2} the optimal control is depicted. We see that it consists of two point sources with intensities which vary smoothly in time.
\begin{figure}[htb]
\centering
\subfloat{\input{images/control}}\quad
\subfloat{\input{images/intensities}}
\caption{Optimal control $\bar u$, $\rg = 10^{-5}$}
\label{recoveredcontrol2}
\end{figure}
The $L^2(I)$ norm of the adjoint state $\bar p$ is shown in \cref{supportIP}.
\begin{figure}[htb]
\centering
\input{images/normp}
\caption{Spatial support of the control determined by $\|\bar p(x)\|_{L^2(I)}=\alpha$.}
\label{supportIP}
\end{figure}
We clearly see that the support of the optimal control correlates with the spatial positions where $\|\bar p(x)\|_{L^2(I)}=\alpha$ holds. The optimal state $\bar y$ is shown in \cref{ex2fullgammadm5}. An upstream soliton is created that matches accurately the objective wave $z$ at terminal time. Naturally, spurious waves are created on the control domain which have no contribution to the cost functional.
\begin{figure}[htb]
\centering
\subfloat{\input{images/state}}\quad
\subfloat{\input{images/terminal_value}}
\caption{Left: Evolution of the optimal state $\bar y$ for $\rg = 10^{-5}$, Right: Terminal state $\bar y(T)$ compared with $z$}
\label{ex2fullgammadm5}
\end{figure}




%%% Local Variables:
%%% mode: latex
%%% TeX-master: "kdv.tex"
%%% End: 